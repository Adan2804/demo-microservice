# ğŸš€ Sistema de Escalado Inteligente - Prueba de Concepto

**Fecha:** 21 de Octubre de 2025  
**Autor:** Adan Moreto Enrriquez

## ğŸ“‹ Resumen Ejecutivo

Sistema de escalado dual que optimiza recursos durante horarios de baja demanda (ahorro de hasta 33%) mientras garantiza capacidad durante horarios crÃ­ticos.

### Beneficios Clave
- âœ… **ReducciÃ³n de Costos:** Hasta 33% de ahorro en horario nocturno
- âœ… **GarantÃ­a de Rendimiento:** Capacidad mÃ­nima asegurada en horario laboral
- âœ… **Decisiones Inteligentes:** Basadas en mÃ©tricas reales (CPU y Memoria)

---

## ğŸ—ï¸ Arquitectura

### Componente 1: Escalado de Prueba (Downscale)
**Archivo:** `05-scaled-object-intelligent-downscale.yaml`

- **Periodo:** 5:00 PM - 6:00 PM (UTC-5, Colombia) â° **HORARIO DE PRUEBA**
- **LÃ³gica:** Reduce de 3 a 2 pods SOLO si CPU y Memoria < 50%
- **Seguridad:** Nunca baja de 2 pods (umbral mÃ­nimo)
- **DuraciÃ³n:** 1 hora para pruebas rÃ¡pidas

### Componente 2: Escalado de Prueba (Upscale)
**Archivo:** `06-scaled-object-intelligent-upscale.yaml`

- **Periodo:** 6:00 PM - 5:00 PM (UTC-5, Colombia) â° **Todo el dÃ­a excepto 5PM-6PM**
- **LÃ³gica:** Garantiza mÃ­nimo 3 pods de forma incondicional
- **Escalado Adicional:** Puede llegar hasta 10 pods si CPU o Memoria > 70%
- **PropÃ³sito:** Restaurar capacidad despuÃ©s del periodo de downscale

---

## ğŸ”„ Flujo de OperaciÃ³n de Prueba (Diario)

```
â° HORARIO DE PRUEBA CONFIGURADO: 5:00 PM - 6:00 PM

00:00 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 17:00 (5PM)
    â”‚                                                      â”‚
    â”‚         MODO UPSCALE (Capacidad Normal)             â”‚
    â”‚         â€¢ MÃ­nimo: 3 pods SIEMPRE                    â”‚
    â”‚         â€¢ MÃ¡ximo: 10 pods (si hay demanda)          â”‚
    â”‚                                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
17:00 (5PM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 18:00 (6PM)
    â”‚                                                      â”‚
    â”‚         MODO DOWNSCALE (Prueba de Ahorro) â°        â”‚
    â”‚         â€¢ EvalÃºa CPU y Memoria                      â”‚
    â”‚         â€¢ Si < 50%: Reduce a 2 pods (ahorro 33%)    â”‚
    â”‚         â€¢ Si >= 50%: Mantiene 3 pods (seguridad)    â”‚
    â”‚         â€¢ DuraciÃ³n: 1 hora                          â”‚
    â”‚                                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                           â”‚
18:00 (6PM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 24:00
    â”‚                                                      â”‚
    â”‚         MODO UPSCALE (Capacidad Restaurada)         â”‚
    â”‚         â€¢ Restaura a 3 pods automÃ¡ticamente         â”‚
    â”‚         â€¢ MÃ¡ximo: 10 pods (si hay demanda)          â”‚
    â”‚                                                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Escenarios de OperaciÃ³n (Horario de Prueba)

### Escenario 1: 5:00 PM - TrÃ¡fico Bajo âœ…
```
Hora: 17:00 (5:00 PM)
CPU: 35% | Memoria: 40%
DecisiÃ³n: âœ… Escalar de 3 â†’ 2 pods
Ahorro: 33% en recursos
DuraciÃ³n: Hasta las 6:00 PM
```

### Escenario 2: 5:00 PM - TrÃ¡fico Alto ğŸ›¡ï¸
```
Hora: 17:00 (5:00 PM)
CPU: 65% | Memoria: 45%
DecisiÃ³n: ğŸ›¡ï¸ Mantener 3 pods
RazÃ³n: CPU supera el umbral del 50%
```

### Escenario 3: 6:00 PM - RestauraciÃ³n de Capacidad ğŸš€
```
Hora: 18:00 (6:00 PM)
Estado Actual: 2 pods
DecisiÃ³n: ğŸš€ Escalar de 2 â†’ 3 pods
RazÃ³n: Fin del periodo de downscale (sin evaluar mÃ©tricas)
```

### Escenario 4: Resto del DÃ­a - Capacidad Normal ğŸ“ˆ
```
Hora: Cualquier hora excepto 5PM-6PM
Estado: 3 pods mÃ­nimo
Comportamiento: Puede escalar hasta 10 pods si hay demanda
```

---

## ğŸš€ GuÃ­a de ImplementaciÃ³n

### Paso 1: Verificar Prerequisitos

```bash
# Verificar que KEDA estÃ© instalado
kubectl get deployment keda-operator -n keda

# Verificar que metrics-server estÃ© instalado (para mÃ©tricas de CPU/Memoria)
kubectl get deployment metrics-server -n kube-system

# Si no estÃ¡ instalado:
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### Paso 2: Desplegar con ArgoCD

Los archivos ya estÃ¡n en `argocd-production/`, ArgoCD los sincronizarÃ¡ automÃ¡ticamente:

```bash
# Ejecutar el script de setup de ArgoCD
cd demo-microservice
./scripts/03-setup-argocd.sh

# Verificar que ArgoCD sincronizÃ³ los ScaledObjects
kubectl get scaledobject -n default
```

### Paso 3: Verificar Despliegue

```bash
# Verificar ScaledObjects
kubectl get scaledobject -n default

# Verificar HPAs generados por KEDA
kubectl get hpa -n default | grep intelligent

# Ver detalles del ScaledObject de downscale
kubectl describe scaledobject demo-microservice-intelligent-downscale -n default

# Ver detalles del ScaledObject de upscale
kubectl describe scaledobject demo-microservice-intelligent-upscale -n default
```

---

## ğŸ“ˆ Monitoreo y ValidaciÃ³n

### Monitoreo en Tiempo Real

```bash
# Monitoreo continuo (actualiza cada 30s)
./scripts/monitor-intelligent-scaling.sh --continuous

# Snapshot Ãºnico del estado actual
./scripts/monitor-intelligent-scaling.sh --snapshot

# Ver solo eventos recientes
./scripts/monitor-intelligent-scaling.sh --events
```

### MÃ©tricas Clave a Observar

1. **NÃºmero de RÃ©plicas vs. Tiempo**
   ```bash
   kubectl get deployment demo-microservice-production-istio -n default -w
   ```

2. **UtilizaciÃ³n de CPU y Memoria**
   ```bash
   kubectl top pods -n default -l app=demo-microservice-istio
   ```

3. **Eventos de Escalado**
   ```bash
   kubectl get events -n default --sort-by='.lastTimestamp' | grep -E "ScaledObject|HorizontalPodAutoscaler"
   ```

4. **Estado de los HPAs**
   ```bash
   kubectl get hpa -n default -w
   ```

### Dashboard de ArgoCD

```bash
# Iniciar ArgoCD Dashboard
./scripts/start-argocd.sh

# Abrir en navegador: https://localhost:8081
# Usuario: admin
# Password: (mostrado en el script)
```

---

## ğŸ§ª Plan de ValidaciÃ³n de la PoC

### Semana 1-2: ObservaciÃ³n y RecolecciÃ³n de Datos

#### DÃ­a 1-3: ValidaciÃ³n de Comportamiento BÃ¡sico
- [ ] Verificar que a las 6:00 AM escala a 3 pods
- [ ] Verificar que a las 10:00 PM evalÃºa las mÃ©tricas
- [ ] Confirmar que no baja de 2 pods nunca
- [ ] Confirmar que no baja de 3 pods durante el dÃ­a

#### DÃ­a 4-7: ValidaciÃ³n de Decisiones Inteligentes
- [ ] Simular carga baja nocturna (< 50%) y verificar downscale
- [ ] Simular carga alta nocturna (>= 50%) y verificar que mantiene 3 pods
- [ ] Verificar la verificaciÃ³n de las 3:00 AM
- [ ] Medir tiempos de respuesta durante transiciones

#### DÃ­a 8-14: ValidaciÃ³n de Rendimiento
- [ ] Medir latencia p95 durante todo el dÃ­a
- [ ] Verificar que no hay degradaciÃ³n en horarios de transiciÃ³n
- [ ] Documentar eventos de escalado inesperados
- [ ] Calcular ahorro real de recursos

### Comandos de SimulaciÃ³n

```bash
# Simular carga alta (para probar que NO escala hacia abajo)
kubectl run load-generator --image=busybox --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://demo-microservice-istio.default.svc.cluster.local; done"

# Detener simulaciÃ³n de carga
kubectl delete pod load-generator

# Forzar evaluaciÃ³n inmediata (para pruebas)
kubectl patch scaledobject demo-microservice-intelligent-downscale -n default --type='json' -p='[{"op": "replace", "path": "/spec/pollingInterval", "value": 10}]'
```

---

## âœ… Criterios de Ã‰xito

La PoC se considerarÃ¡ exitosa si:

1. **Ahorro de Recursos**
   - âœ… ReducciÃ³n de al menos 20% en consumo nocturno
   - âœ… Pods se reducen a 2 durante horario de baja demanda

2. **GarantÃ­a de Rendimiento**
   - âœ… Latencia p95 se mantiene dentro del SLA
   - âœ… No hay degradaciÃ³n durante transiciones
   - âœ… Capacidad mÃ­nima garantizada a las 6:00 AM

3. **Decisiones Inteligentes**
   - âœ… No escala hacia abajo si la carga es alta
   - âœ… Responde rÃ¡pidamente a picos de demanda
   - âœ… EstabilizaciÃ³n adecuada (sin flapping)

4. **OperaciÃ³n Confiable**
   - âœ… Sin errores en logs de KEDA
   - âœ… HPAs funcionan correctamente
   - âœ… Transiciones suaves entre periodos

---

## ğŸ”§ Troubleshooting

### Problema: ScaledObject no se crea

```bash
# Verificar que KEDA estÃ© instalado
kubectl get deployment keda-operator -n keda

# Ver logs de KEDA
kubectl logs -n keda deployment/keda-operator
```

### Problema: No escala segÃºn el horario

```bash
# Verificar la zona horaria del cluster
kubectl get scaledobject demo-microservice-intelligent-upscale -n default -o yaml | grep timezone

# Verificar la hora actual en el pod de KEDA
kubectl exec -n keda deployment/keda-operator -- date
```

### Problema: MÃ©tricas no disponibles

```bash
# Verificar metrics-server
kubectl get deployment metrics-server -n kube-system

# Instalar metrics-server si no estÃ¡
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Para Minikube, habilitar metrics-server
minikube addons enable metrics-server
```

### Problema: Conflicto entre los dos ScaledObjects

```bash
# Verificar que solo uno estÃ© activo a la vez
kubectl get scaledobject -n default -o wide

# Ver eventos de conflicto
kubectl get events -n default | grep -i conflict
```

---

## ğŸ“ Notas Importantes

### Consideraciones de Zona Horaria
- Los horarios estÃ¡n configurados para **America/Bogota (UTC-5)**
- **Horario de Prueba:** 5:00 PM - 6:00 PM (1 hora)
- Ajustar si el cluster estÃ¡ en otra zona horaria
- Verificar que KEDA soporte la zona horaria configurada

### Periodo de EstabilizaciÃ³n
- **Downscale:** 10 minutos (600s) - Conservador para evitar flapping
- **Upscale:** Sin espera (0s) - Respuesta inmediata a demanda
- **Nota:** Con 1 hora de prueba, el downscale puede tardar hasta 10 minutos en activarse

### Umbrales de Escalado
- **Periodo 5PM-6PM:** CPU y Memoria < 50% para reducir
- **Resto del dÃ­a:** CPU o Memoria > 70% para escalar mÃ¡s allÃ¡ de 3 pods

### InteracciÃ³n con ArgoCD
- ArgoCD gestiona los ScaledObjects como cualquier otro recurso
- Los cambios manuales serÃ¡n revertidos por ArgoCD
- Para modificar, editar los archivos en `argocd-production/` y hacer commit

---

## ğŸ“š Referencias

- [KEDA Documentation](https://keda.sh/docs/)
- [KEDA Cron Scaler](https://keda.sh/docs/scalers/cron/)
- [KEDA CPU Scaler](https://keda.sh/docs/scalers/cpu/)
- [KEDA Memory Scaler](https://keda.sh/docs/scalers/memory/)
- [HPA Behavior Configuration](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#configurable-scaling-behavior)

---

## ğŸ¯ PrÃ³ximos Pasos

1. **Desplegar la PoC**
   ```bash
   ./scripts/03-setup-argocd.sh
   ```

2. **Iniciar Monitoreo**
   ```bash
   ./scripts/monitor-intelligent-scaling.sh --continuous
   ```

3. **Observar Durante 2 Semanas**
   - Documentar comportamiento
   - Recolectar mÃ©tricas
   - Ajustar umbrales si es necesario

4. **Evaluar Resultados**
   - Calcular ahorro real
   - Verificar cumplimiento de SLA
   - Decidir si se implementa en producciÃ³n

---

**Â¡Buena suerte con la Prueba de Concepto! ğŸš€**
